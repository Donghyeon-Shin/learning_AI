{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57efd8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Mixed Precision을 위한 스케일러 초기화\n",
    "scaler_resnet_50 = GradScaler('cuda')\n",
    "scaler_se_resnet_50 = GradScaler('cuda')\n",
    "\n",
    "batch_size = 512 # 배치 크기\n",
    "\n",
    "transfrom = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# 데이터셋 다운로드\n",
    "full_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transfrom)\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 데이터 증강\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "# 검증/테스트 데이터\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 데이터셋 다운로드\n",
    "full_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c233c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Train/Validation 분할 (80:20)\n",
    "train_size = int(0.8 * len(full_trainset))\n",
    "val_size = len(full_trainset) - train_size\n",
    "\n",
    "datasets = random_split(full_trainset, [train_size, val_size])\n",
    "trainset = datasets[0]  # 학습용\n",
    "valset = datasets[1]     # 검증용\n",
    "\n",
    "\n",
    "# 데이터셋 불러오기\n",
    "# DataLoader : 데이터셋을 배치 단위로 관리하는 역할\n",
    "    # batch_size : 배치 크기\n",
    "    # shuffle : 데이터를 섞을지 여부\n",
    "    # num_workers : 데이터 로드에 사용할 쓰레드 수\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18049a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# SEBlock : Squeeze-and-Excitation Block\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1) # Squeeze\n",
    "\n",
    "        # Excitation\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_channels // reduction, in_channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        z = self.avg_pool(x).view(b, c) # 딥러닝에서는 이미지를 batch 수 만큼 한번에 진행\n",
    "        s = self.fc(z).view(b, c, 1, 1) # 채널 수 만큼 출력\n",
    "        return x * s # scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae55adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ResNetBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, use_se=False, reduction=16):\n",
    "        super(ResNetBottleneck, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "\n",
    "        # SEBlock 추가 여부\n",
    "        if use_se:\n",
    "            self.se = SEBlock(planes * self.expansion, reduction)\n",
    "        else:\n",
    "            self.se = nn.Identity() # SEBlock 추가 안할 경우 그냥 통과\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes * self.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * self.expansion)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = self.se(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc0e56c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, use_se=False, reduction=16):\n",
    "        super(Net, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        # 채널 수 3 -> 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # _make_layer 함수 호출하여 여러 개의 블록 그룹 생성\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], 1, use_se, reduction)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], 2, use_se, reduction)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], 2, use_se, reduction)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], 2, False, reduction) # 마지막 블록은 SEBlock 추가 안함\n",
    "\n",
    "        # average pooling 레이어 사용\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # 완전 연결 레이어(Fully Connected Layer) 512 * block.expansion -> 10개의 클래스로 분류\n",
    "        self.fc = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride, use_se=False, reduction=16):\n",
    "        strides = [stride] + [1] * (num_blocks - 1) # 첫 번째 블록은 stride, 나머지는 1\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, use_se, reduction))\n",
    "            self.in_planes = planes * block.expansion # 채널 수 증가\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e847605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 layer resnet\n",
    "resnet_50 = Net(ResNetBottleneck, [3, 4, 6, 3])\n",
    "resnet_50_loss = []\n",
    "resnet_50_error = []\n",
    "\n",
    "se_resnet_50 = Net(ResNetBottleneck, [3, 4, 6, 3], use_se=True, reduction=16)\n",
    "se_resnet_50_loss = []\n",
    "se_resnet_50_error = []\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "resnet_50 = resnet_50.to(device)\n",
    "se_resnet_50 = se_resnet_50.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "344a1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# 크로스 엔트로피 손실 함수 사용\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 초기 학습률을 더 낮게 설정 (경사 폭발 방지)\n",
    "# ResNet-50과 같은 깊은 네트워크에서는 더 보수적인 접근 필요\n",
    "\n",
    "# 모멘텀 0.9, weight_decay 1e-4\n",
    "resnet_50_optimizer = optim.SGD(resnet_50.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "se_resnet_50_optimizer = optim.SGD(se_resnet_50.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "# 학습률 스케줄링 - 더 보수적으로 설정\n",
    "# patience를 늘리고 factor를 줄여서 더 점진적으로 학습률 감소\n",
    "resnet_50_scheduler = optim.lr_scheduler.ReduceLROnPlateau(resnet_50_optimizer, mode='min', factor=0.5, patience=10, min_lr=1e-6)\n",
    "se_resnet_50_scheduler = optim.lr_scheduler.ReduceLROnPlateau(se_resnet_50_optimizer, mode='min', factor=0.5, patience=10, min_lr=1e-6)\n",
    "\n",
    "# 100번 에포크 학습\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc984c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수 (top1 error rate, top5 error rate)\n",
    "def evaluate_model(model, data_loader, is_top5=False):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)  # GPU로 이동\n",
    "            labels = labels.to(device)  # GPU로 이동\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            if is_top5:\n",
    "                _, top5 = outputs.topk(5, dim=1)\n",
    "                total_correct += (top5 == labels.unsqueeze(1)).any(dim=1).sum().item()\n",
    "            else:\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    return (1 - total_correct / total_samples) * 100           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3314e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "Current LR - SE-ResNet50: 0.001000\n",
      "\n",
      "Epoch 2/100\n",
      "Current LR - SE-ResNet50: 0.001000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Mixed Precision 역전파\u001b[39;00m\n\u001b[32m     25\u001b[39m scaler_se_resnet_50.scale(loss_se_resnet_50).backward()\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mscaler_se_resnet_50\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mse_resnet_50_optimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m scaler_se_resnet_50.update()\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# 배치 손실 합계 계산\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\workspace-vom\\env\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:465\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    459\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    462\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    463\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\workspace-vom\\env\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:359\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    352\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    353\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    356\u001b[39m     **kwargs: Any,\n\u001b[32m    357\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    358\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf_per_device\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    360\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\workspace-vom\\env\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:359\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    352\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    353\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    356\u001b[39m     **kwargs: Any,\n\u001b[32m    357\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    358\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    360\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# SE-ResNet-50 model 학습 (스케줄링 적용)\n",
    "for epoch in range(num_epochs):\n",
    "    # 모델을 학습 모드로 설정\n",
    "    se_resnet_50.train()\n",
    "    \n",
    "    running_loss_se_resnet_50 = 0.0\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Current LR - SE-ResNet50: {se_resnet_50_optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)  # GPU로 이동\n",
    "        labels = labels.to(device)  # GPU로 이동\n",
    "\n",
    "        # SE-ResNet-50 학습 (Mixed Precision)\n",
    "        se_resnet_50_optimizer.zero_grad()\n",
    "\n",
    "        # Mixed Precision 순전파\n",
    "        with autocast('cuda'):\n",
    "            outputs_se_resnet_50 = se_resnet_50(inputs)\n",
    "            loss_se_resnet_50 = criterion(outputs_se_resnet_50, labels)\n",
    "        \n",
    "        # Mixed Precision 역전파\n",
    "        scaler_se_resnet_50.scale(loss_se_resnet_50).backward()\n",
    "        scaler_se_resnet_50.step(se_resnet_50_optimizer)\n",
    "        scaler_se_resnet_50.update()\n",
    "    \n",
    "\n",
    "        # 배치 손실 합계 계산\n",
    "        running_loss_se_resnet_50 += loss_se_resnet_50.item()\n",
    "\n",
    "        # 20 배치마다 검증 및 출력\n",
    "        if (i + 1) % 20 == 0:\n",
    "            val_error_se_resnet_50 = evaluate_model(se_resnet_50, val_loader)\n",
    "\n",
    "            se_resnet_50_error.append(val_error_se_resnet_50)\n",
    "\n",
    "            avg_loss_se_resnet_50 = running_loss_se_resnet_50 / 20\n",
    "            \n",
    "            se_resnet_50_loss.append(avg_loss_se_resnet_50)\n",
    "\n",
    "            print(f\"Batch {i + 1}: SE-ResNet50 Loss = {avg_loss_se_resnet_50:.4f}, Error = {val_error_se_resnet_50:.2f}%\")\n",
    "            \n",
    "            # running_loss 초기화\n",
    "            running_loss_se_resnet_50 = 0.0\n",
    "    \n",
    "    # 에포크 끝에서 스케줄러 업데이트 (검증 오류율 기준)\n",
    "    if len(se_resnet_50_error) > 0:\n",
    "        se_resnet_50_scheduler.step(se_resnet_50_error[-1])\n",
    "\n",
    "print(\"학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f33eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE-ResNet-50 model 저장\n",
    "torch.save(se_resnet_50.state_dict(), 'se_resnet_50.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa8069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 2.3660, Error = 79.11%\n",
      "Batch 200: ResNet50 Loss = 2.1629, Error = 79.27%\n",
      "Batch 300: ResNet50 Loss = 1.9967, Error = 74.08%\n",
      "Batch 400: ResNet50 Loss = 1.9015, Error = 72.03%\n",
      "Batch 500: ResNet50 Loss = 1.8337, Error = 66.34%\n",
      "Batch 600: ResNet50 Loss = 1.8026, Error = 67.05%\n",
      "Batch 700: ResNet50 Loss = 1.7470, Error = 64.16%\n",
      "Batch 800: ResNet50 Loss = 1.7383, Error = 65.14%\n",
      "Batch 900: ResNet50 Loss = 1.6419, Error = 62.37%\n",
      "Batch 1000: ResNet50 Loss = 1.7050, Error = 63.13%\n",
      "Batch 1100: ResNet50 Loss = 1.6630, Error = 60.83%\n",
      "Batch 1200: ResNet50 Loss = 1.6297, Error = 57.69%\n",
      "\n",
      "Epoch 2/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 1.8739, Error = 62.86%\n",
      "Batch 200: ResNet50 Loss = 1.9308, Error = 65.24%\n",
      "Batch 300: ResNet50 Loss = 1.7343, Error = 63.69%\n",
      "Batch 400: ResNet50 Loss = 1.6330, Error = 60.63%\n",
      "Batch 500: ResNet50 Loss = 1.6702, Error = 62.15%\n",
      "Batch 600: ResNet50 Loss = 1.5677, Error = 59.21%\n",
      "Batch 700: ResNet50 Loss = 1.5802, Error = 58.15%\n",
      "Batch 800: ResNet50 Loss = 1.5127, Error = 55.77%\n",
      "Batch 900: ResNet50 Loss = 1.5104, Error = 53.60%\n",
      "Batch 1000: ResNet50 Loss = 1.4330, Error = 51.00%\n",
      "Batch 1100: ResNet50 Loss = 1.5052, Error = 53.86%\n",
      "Batch 1200: ResNet50 Loss = 1.4658, Error = 52.68%\n",
      "\n",
      "Epoch 3/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 1.6217, Error = 56.50%\n",
      "Batch 200: ResNet50 Loss = 1.5302, Error = 54.57%\n",
      "Batch 300: ResNet50 Loss = 1.4680, Error = 52.01%\n",
      "Batch 400: ResNet50 Loss = 1.4317, Error = 51.15%\n",
      "Batch 500: ResNet50 Loss = 1.3765, Error = 52.02%\n",
      "Batch 600: ResNet50 Loss = 1.3734, Error = 50.87%\n",
      "Batch 700: ResNet50 Loss = 1.3784, Error = 53.59%\n",
      "Batch 800: ResNet50 Loss = 1.3550, Error = 51.16%\n",
      "Batch 900: ResNet50 Loss = 1.3572, Error = 49.58%\n",
      "Batch 1000: ResNet50 Loss = 1.3288, Error = 47.83%\n",
      "Batch 1100: ResNet50 Loss = 1.2818, Error = 49.37%\n",
      "Batch 1200: ResNet50 Loss = 1.3369, Error = 46.41%\n",
      "\n",
      "Epoch 4/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 1.4278, Error = 51.68%\n",
      "Batch 200: ResNet50 Loss = 1.2878, Error = 48.31%\n",
      "Batch 300: ResNet50 Loss = 1.2942, Error = 45.85%\n",
      "Batch 400: ResNet50 Loss = 1.2875, Error = 50.20%\n",
      "Batch 500: ResNet50 Loss = 1.2669, Error = 44.51%\n",
      "Batch 600: ResNet50 Loss = 1.2553, Error = 49.78%\n",
      "Batch 700: ResNet50 Loss = 1.2602, Error = 44.81%\n",
      "Batch 800: ResNet50 Loss = 1.2158, Error = 45.64%\n",
      "Batch 900: ResNet50 Loss = 1.2260, Error = 43.79%\n",
      "Batch 1000: ResNet50 Loss = 1.2293, Error = 43.14%\n",
      "Batch 1100: ResNet50 Loss = 1.2061, Error = 45.27%\n",
      "Batch 1200: ResNet50 Loss = 1.1876, Error = 43.67%\n",
      "\n",
      "Epoch 5/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 1.2720, Error = 46.31%\n",
      "Batch 200: ResNet50 Loss = 1.2280, Error = 43.74%\n",
      "Batch 300: ResNet50 Loss = 1.1865, Error = 42.17%\n",
      "Batch 400: ResNet50 Loss = 1.1810, Error = 41.78%\n",
      "Batch 500: ResNet50 Loss = 1.1768, Error = 42.52%\n",
      "Batch 600: ResNet50 Loss = 1.1478, Error = 41.40%\n",
      "Batch 700: ResNet50 Loss = 1.1496, Error = 41.17%\n",
      "Batch 800: ResNet50 Loss = 1.1570, Error = 43.80%\n",
      "Batch 900: ResNet50 Loss = 1.1134, Error = 40.11%\n",
      "Batch 1000: ResNet50 Loss = 1.0852, Error = 40.36%\n",
      "Batch 1100: ResNet50 Loss = 1.1193, Error = 38.27%\n",
      "Batch 1200: ResNet50 Loss = 1.0959, Error = 37.68%\n",
      "\n",
      "Epoch 6/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 1.2300, Error = 40.68%\n",
      "Batch 200: ResNet50 Loss = 1.1477, Error = 39.30%\n",
      "Batch 300: ResNet50 Loss = 1.0748, Error = 41.62%\n",
      "Batch 400: ResNet50 Loss = 1.1238, Error = 38.25%\n",
      "Batch 500: ResNet50 Loss = 1.0315, Error = 41.35%\n",
      "Batch 600: ResNet50 Loss = 1.0208, Error = 36.66%\n",
      "Batch 700: ResNet50 Loss = 1.0281, Error = 40.21%\n",
      "Batch 800: ResNet50 Loss = 1.0358, Error = 36.72%\n",
      "Batch 900: ResNet50 Loss = 0.9760, Error = 41.83%\n",
      "Batch 1000: ResNet50 Loss = 1.0375, Error = 38.53%\n",
      "Batch 1100: ResNet50 Loss = 1.0287, Error = 37.27%\n",
      "Batch 1200: ResNet50 Loss = 1.0334, Error = 39.45%\n",
      "\n",
      "Epoch 7/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 1.0960, Error = 37.19%\n",
      "Batch 200: ResNet50 Loss = 1.0232, Error = 35.98%\n",
      "Batch 300: ResNet50 Loss = 0.9710, Error = 36.47%\n",
      "Batch 400: ResNet50 Loss = 0.9971, Error = 33.92%\n",
      "Batch 500: ResNet50 Loss = 0.9675, Error = 36.02%\n",
      "Batch 600: ResNet50 Loss = 0.9438, Error = 34.01%\n",
      "Batch 700: ResNet50 Loss = 0.9492, Error = 33.73%\n",
      "Batch 800: ResNet50 Loss = 0.8962, Error = 34.97%\n",
      "Batch 900: ResNet50 Loss = 0.9544, Error = 34.20%\n",
      "Batch 1000: ResNet50 Loss = 0.9646, Error = 34.08%\n",
      "Batch 1100: ResNet50 Loss = 0.9536, Error = 37.41%\n",
      "Batch 1200: ResNet50 Loss = 0.9456, Error = 34.25%\n",
      "\n",
      "Epoch 8/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.9448, Error = 36.84%\n",
      "Batch 200: ResNet50 Loss = 0.9330, Error = 32.78%\n",
      "Batch 300: ResNet50 Loss = 0.9148, Error = 34.67%\n",
      "Batch 400: ResNet50 Loss = 0.9274, Error = 34.19%\n",
      "Batch 500: ResNet50 Loss = 0.9354, Error = 34.20%\n",
      "Batch 600: ResNet50 Loss = 0.8980, Error = 38.04%\n",
      "Batch 700: ResNet50 Loss = 0.9022, Error = 33.72%\n",
      "Batch 800: ResNet50 Loss = 0.8883, Error = 31.10%\n",
      "Batch 900: ResNet50 Loss = 0.8845, Error = 34.12%\n",
      "Batch 1000: ResNet50 Loss = 0.9182, Error = 33.82%\n",
      "Batch 1100: ResNet50 Loss = 0.8709, Error = 33.03%\n",
      "Batch 1200: ResNet50 Loss = 0.8683, Error = 32.64%\n",
      "\n",
      "Epoch 9/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.9317, Error = 32.25%\n",
      "Batch 200: ResNet50 Loss = 0.9313, Error = 32.28%\n",
      "Batch 300: ResNet50 Loss = 0.8470, Error = 33.29%\n",
      "Batch 400: ResNet50 Loss = 0.8339, Error = 31.79%\n",
      "Batch 500: ResNet50 Loss = 0.8525, Error = 31.54%\n",
      "Batch 600: ResNet50 Loss = 0.8466, Error = 31.93%\n",
      "Batch 700: ResNet50 Loss = 0.8210, Error = 32.93%\n",
      "Batch 800: ResNet50 Loss = 0.8888, Error = 33.44%\n",
      "Batch 900: ResNet50 Loss = 0.8723, Error = 30.16%\n",
      "Batch 1000: ResNet50 Loss = 0.7985, Error = 30.49%\n",
      "Batch 1100: ResNet50 Loss = 0.8273, Error = 31.11%\n",
      "Batch 1200: ResNet50 Loss = 0.8215, Error = 30.35%\n",
      "\n",
      "Epoch 10/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.9098, Error = 33.07%\n",
      "Batch 200: ResNet50 Loss = 0.8788, Error = 29.20%\n",
      "Batch 300: ResNet50 Loss = 0.7800, Error = 29.45%\n",
      "Batch 400: ResNet50 Loss = 0.8272, Error = 28.77%\n",
      "Batch 500: ResNet50 Loss = 0.7786, Error = 36.86%\n",
      "Batch 600: ResNet50 Loss = 0.8373, Error = 28.07%\n",
      "Batch 700: ResNet50 Loss = 0.7641, Error = 28.25%\n",
      "Batch 800: ResNet50 Loss = 0.8049, Error = 32.30%\n",
      "Batch 900: ResNet50 Loss = 0.7924, Error = 29.77%\n",
      "Batch 1000: ResNet50 Loss = 0.7726, Error = 29.83%\n",
      "Batch 1100: ResNet50 Loss = 0.8047, Error = 27.98%\n",
      "Batch 1200: ResNet50 Loss = 0.7611, Error = 30.58%\n",
      "\n",
      "Epoch 11/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.8665, Error = 28.57%\n",
      "Batch 200: ResNet50 Loss = 0.7907, Error = 30.86%\n",
      "Batch 300: ResNet50 Loss = 0.7806, Error = 29.02%\n",
      "Batch 400: ResNet50 Loss = 0.7580, Error = 27.44%\n",
      "Batch 500: ResNet50 Loss = 0.7395, Error = 28.16%\n",
      "Batch 600: ResNet50 Loss = 0.7700, Error = 29.87%\n",
      "Batch 700: ResNet50 Loss = 0.7381, Error = 29.43%\n",
      "Batch 800: ResNet50 Loss = 0.7743, Error = 28.09%\n",
      "Batch 900: ResNet50 Loss = 0.7650, Error = 27.90%\n",
      "Batch 1000: ResNet50 Loss = 0.7563, Error = 29.72%\n",
      "Batch 1100: ResNet50 Loss = 0.6945, Error = 29.18%\n",
      "Batch 1200: ResNet50 Loss = 0.7660, Error = 29.86%\n",
      "\n",
      "Epoch 12/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.7912, Error = 26.75%\n",
      "Batch 200: ResNet50 Loss = 0.7665, Error = 26.95%\n",
      "Batch 300: ResNet50 Loss = 0.7404, Error = 26.90%\n",
      "Batch 400: ResNet50 Loss = 0.7556, Error = 28.46%\n",
      "Batch 500: ResNet50 Loss = 0.7314, Error = 28.29%\n",
      "Batch 600: ResNet50 Loss = 0.7305, Error = 28.11%\n",
      "Batch 700: ResNet50 Loss = 0.7004, Error = 28.22%\n",
      "Batch 800: ResNet50 Loss = 0.7194, Error = 28.22%\n",
      "Batch 900: ResNet50 Loss = 0.7044, Error = 26.86%\n",
      "Batch 1000: ResNet50 Loss = 0.7158, Error = 29.30%\n",
      "Batch 1100: ResNet50 Loss = 0.7309, Error = 25.99%\n",
      "Batch 1200: ResNet50 Loss = 0.7403, Error = 25.94%\n",
      "\n",
      "Epoch 13/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.7613, Error = 29.99%\n",
      "Batch 200: ResNet50 Loss = 0.7409, Error = 26.23%\n",
      "Batch 300: ResNet50 Loss = 0.6867, Error = 28.29%\n",
      "Batch 400: ResNet50 Loss = 0.6746, Error = 27.04%\n",
      "Batch 500: ResNet50 Loss = 0.7033, Error = 27.98%\n",
      "Batch 600: ResNet50 Loss = 0.6990, Error = 25.31%\n",
      "Batch 700: ResNet50 Loss = 0.6899, Error = 26.93%\n",
      "Batch 800: ResNet50 Loss = 0.6515, Error = 26.04%\n",
      "Batch 900: ResNet50 Loss = 0.6767, Error = 27.30%\n",
      "Batch 1000: ResNet50 Loss = 0.7266, Error = 25.23%\n",
      "Batch 1100: ResNet50 Loss = 0.6593, Error = 27.39%\n",
      "Batch 1200: ResNet50 Loss = 0.6679, Error = 26.68%\n",
      "\n",
      "Epoch 14/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.6938, Error = 27.76%\n",
      "Batch 200: ResNet50 Loss = 0.7017, Error = 28.49%\n",
      "Batch 300: ResNet50 Loss = 0.6567, Error = 27.46%\n",
      "Batch 400: ResNet50 Loss = 0.6530, Error = 25.64%\n",
      "Batch 500: ResNet50 Loss = 0.6700, Error = 25.53%\n",
      "Batch 600: ResNet50 Loss = 0.6412, Error = 26.12%\n",
      "Batch 700: ResNet50 Loss = 0.6598, Error = 25.00%\n",
      "Batch 800: ResNet50 Loss = 0.6596, Error = 26.75%\n",
      "Batch 900: ResNet50 Loss = 0.6153, Error = 26.49%\n",
      "Batch 1000: ResNet50 Loss = 0.6476, Error = 26.58%\n",
      "Batch 1100: ResNet50 Loss = 0.6761, Error = 27.68%\n",
      "Batch 1200: ResNet50 Loss = 0.6816, Error = 26.42%\n",
      "\n",
      "Epoch 15/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.7216, Error = 25.74%\n",
      "Batch 200: ResNet50 Loss = 0.6248, Error = 25.70%\n",
      "Batch 300: ResNet50 Loss = 0.6143, Error = 28.25%\n",
      "Batch 400: ResNet50 Loss = 0.6357, Error = 24.96%\n",
      "Batch 500: ResNet50 Loss = 0.6095, Error = 24.32%\n",
      "Batch 600: ResNet50 Loss = 0.6204, Error = 25.11%\n",
      "Batch 700: ResNet50 Loss = 0.6570, Error = 24.01%\n",
      "Batch 800: ResNet50 Loss = 0.6320, Error = 26.89%\n",
      "Batch 900: ResNet50 Loss = 0.6289, Error = 24.88%\n",
      "Batch 1000: ResNet50 Loss = 0.6220, Error = 24.37%\n",
      "Batch 1100: ResNet50 Loss = 0.6388, Error = 25.43%\n",
      "Batch 1200: ResNet50 Loss = 0.6170, Error = 24.95%\n",
      "\n",
      "Epoch 16/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.6788, Error = 24.26%\n",
      "Batch 200: ResNet50 Loss = 0.6065, Error = 24.93%\n",
      "Batch 300: ResNet50 Loss = 0.5902, Error = 22.57%\n",
      "Batch 400: ResNet50 Loss = 0.5918, Error = 23.15%\n",
      "Batch 500: ResNet50 Loss = 0.5607, Error = 26.78%\n",
      "Batch 600: ResNet50 Loss = 0.6140, Error = 23.44%\n",
      "Batch 700: ResNet50 Loss = 0.5666, Error = 23.44%\n",
      "Batch 800: ResNet50 Loss = 0.5874, Error = 27.53%\n",
      "Batch 900: ResNet50 Loss = 0.6202, Error = 25.11%\n",
      "Batch 1000: ResNet50 Loss = 0.6001, Error = 22.81%\n",
      "Batch 1100: ResNet50 Loss = 0.6128, Error = 23.72%\n",
      "Batch 1200: ResNet50 Loss = 0.5917, Error = 24.63%\n",
      "\n",
      "Epoch 17/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.6254, Error = 22.58%\n",
      "Batch 200: ResNet50 Loss = 0.5787, Error = 24.67%\n",
      "Batch 300: ResNet50 Loss = 0.5955, Error = 24.20%\n",
      "Batch 400: ResNet50 Loss = 0.5833, Error = 25.75%\n",
      "Batch 500: ResNet50 Loss = 0.5638, Error = 23.81%\n",
      "Batch 600: ResNet50 Loss = 0.5799, Error = 24.26%\n",
      "Batch 700: ResNet50 Loss = 0.5522, Error = 24.19%\n",
      "Batch 800: ResNet50 Loss = 0.5808, Error = 25.19%\n",
      "Batch 900: ResNet50 Loss = 0.5865, Error = 25.84%\n",
      "Batch 1000: ResNet50 Loss = 0.5801, Error = 23.11%\n",
      "Batch 1100: ResNet50 Loss = 0.5926, Error = 22.68%\n",
      "Batch 1200: ResNet50 Loss = 0.5774, Error = 21.68%\n",
      "\n",
      "Epoch 18/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.6252, Error = 22.43%\n",
      "Batch 200: ResNet50 Loss = 0.5455, Error = 22.87%\n",
      "Batch 300: ResNet50 Loss = 0.5791, Error = 23.29%\n",
      "Batch 400: ResNet50 Loss = 0.5294, Error = 23.79%\n",
      "Batch 500: ResNet50 Loss = 0.5443, Error = 22.14%\n",
      "Batch 600: ResNet50 Loss = 0.5670, Error = 22.32%\n",
      "Batch 700: ResNet50 Loss = 0.5482, Error = 21.62%\n",
      "Batch 800: ResNet50 Loss = 0.5720, Error = 20.56%\n",
      "Batch 900: ResNet50 Loss = 0.5495, Error = 21.38%\n",
      "Batch 1000: ResNet50 Loss = 0.5363, Error = 21.38%\n",
      "Batch 1100: ResNet50 Loss = 0.5376, Error = 23.92%\n",
      "Batch 1200: ResNet50 Loss = 0.5594, Error = 22.91%\n",
      "\n",
      "Epoch 19/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.5662, Error = 21.97%\n",
      "Batch 200: ResNet50 Loss = 0.5508, Error = 23.00%\n",
      "Batch 300: ResNet50 Loss = 0.5477, Error = 25.43%\n",
      "Batch 400: ResNet50 Loss = 0.5230, Error = 21.48%\n",
      "Batch 500: ResNet50 Loss = 0.5148, Error = 23.30%\n",
      "Batch 600: ResNet50 Loss = 0.5290, Error = 22.06%\n",
      "Batch 700: ResNet50 Loss = 0.5009, Error = 22.43%\n",
      "Batch 800: ResNet50 Loss = 0.5154, Error = 26.35%\n",
      "Batch 900: ResNet50 Loss = 0.5498, Error = 22.13%\n",
      "Batch 1000: ResNet50 Loss = 0.5500, Error = 22.16%\n",
      "Batch 1100: ResNet50 Loss = 0.5065, Error = 21.61%\n",
      "Batch 1200: ResNet50 Loss = 0.5718, Error = 25.11%\n",
      "\n",
      "Epoch 20/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.5375, Error = 21.15%\n",
      "Batch 200: ResNet50 Loss = 0.5219, Error = 20.63%\n",
      "Batch 300: ResNet50 Loss = 0.4746, Error = 20.53%\n",
      "Batch 400: ResNet50 Loss = 0.5284, Error = 21.32%\n",
      "Batch 500: ResNet50 Loss = 0.5346, Error = 20.77%\n",
      "Batch 600: ResNet50 Loss = 0.5224, Error = 19.98%\n",
      "Batch 700: ResNet50 Loss = 0.5002, Error = 23.23%\n",
      "Batch 800: ResNet50 Loss = 0.5197, Error = 20.89%\n",
      "Batch 900: ResNet50 Loss = 0.4943, Error = 19.70%\n",
      "Batch 1000: ResNet50 Loss = 0.5089, Error = 20.33%\n",
      "Batch 1100: ResNet50 Loss = 0.5212, Error = 22.77%\n",
      "Batch 1200: ResNet50 Loss = 0.4940, Error = 21.60%\n",
      "\n",
      "Epoch 21/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.5313, Error = 20.75%\n",
      "Batch 200: ResNet50 Loss = 0.5157, Error = 21.82%\n",
      "Batch 300: ResNet50 Loss = 0.4820, Error = 21.34%\n",
      "Batch 400: ResNet50 Loss = 0.5014, Error = 20.40%\n",
      "Batch 500: ResNet50 Loss = 0.5059, Error = 21.54%\n",
      "Batch 600: ResNet50 Loss = 0.4753, Error = 19.72%\n",
      "Batch 700: ResNet50 Loss = 0.4680, Error = 20.52%\n",
      "Batch 800: ResNet50 Loss = 0.4752, Error = 21.51%\n",
      "Batch 900: ResNet50 Loss = 0.4951, Error = 19.95%\n",
      "Batch 1000: ResNet50 Loss = 0.4636, Error = 19.30%\n",
      "Batch 1100: ResNet50 Loss = 0.4891, Error = 20.03%\n",
      "Batch 1200: ResNet50 Loss = 0.4962, Error = 20.73%\n",
      "\n",
      "Epoch 22/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.4978, Error = 19.08%\n",
      "Batch 200: ResNet50 Loss = 0.4385, Error = 20.94%\n",
      "Batch 300: ResNet50 Loss = 0.4648, Error = 18.86%\n",
      "Batch 400: ResNet50 Loss = 0.4630, Error = 21.80%\n",
      "Batch 500: ResNet50 Loss = 0.4766, Error = 19.85%\n",
      "Batch 600: ResNet50 Loss = 0.4503, Error = 19.94%\n",
      "Batch 700: ResNet50 Loss = 0.5009, Error = 20.63%\n",
      "Batch 800: ResNet50 Loss = 0.4752, Error = 18.83%\n",
      "Batch 900: ResNet50 Loss = 0.4616, Error = 18.90%\n",
      "Batch 1000: ResNet50 Loss = 0.4405, Error = 19.29%\n",
      "Batch 1100: ResNet50 Loss = 0.4885, Error = 20.49%\n",
      "Batch 1200: ResNet50 Loss = 0.4769, Error = 20.16%\n",
      "\n",
      "Epoch 23/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.4973, Error = 19.42%\n",
      "Batch 200: ResNet50 Loss = 0.4930, Error = 18.53%\n",
      "Batch 300: ResNet50 Loss = 0.4662, Error = 19.06%\n",
      "Batch 400: ResNet50 Loss = 0.4554, Error = 20.30%\n",
      "Batch 500: ResNet50 Loss = 0.4453, Error = 19.24%\n",
      "Batch 600: ResNet50 Loss = 0.4614, Error = 20.70%\n",
      "Batch 700: ResNet50 Loss = 0.4339, Error = 19.52%\n",
      "Batch 800: ResNet50 Loss = 0.4248, Error = 21.64%\n",
      "Batch 900: ResNet50 Loss = 0.4580, Error = 19.92%\n",
      "Batch 1000: ResNet50 Loss = 0.4470, Error = 19.53%\n",
      "Batch 1100: ResNet50 Loss = 0.4438, Error = 18.83%\n",
      "Batch 1200: ResNet50 Loss = 0.4474, Error = 19.42%\n",
      "\n",
      "Epoch 24/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.4751, Error = 18.02%\n",
      "Batch 200: ResNet50 Loss = 0.4379, Error = 20.12%\n",
      "Batch 300: ResNet50 Loss = 0.4144, Error = 18.75%\n",
      "Batch 400: ResNet50 Loss = 0.4093, Error = 19.10%\n",
      "Batch 500: ResNet50 Loss = 0.4138, Error = 22.16%\n",
      "Batch 600: ResNet50 Loss = 0.4303, Error = 18.95%\n",
      "Batch 700: ResNet50 Loss = 0.4050, Error = 19.23%\n",
      "Batch 800: ResNet50 Loss = 0.4240, Error = 18.74%\n",
      "Batch 900: ResNet50 Loss = 0.4413, Error = 19.72%\n",
      "Batch 1000: ResNet50 Loss = 0.4488, Error = 20.50%\n",
      "Batch 1100: ResNet50 Loss = 0.4425, Error = 19.72%\n",
      "Batch 1200: ResNet50 Loss = 0.4262, Error = 19.04%\n",
      "\n",
      "Epoch 25/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.4290, Error = 18.17%\n",
      "Batch 200: ResNet50 Loss = 0.4199, Error = 17.83%\n",
      "Batch 300: ResNet50 Loss = 0.4236, Error = 18.97%\n",
      "Batch 400: ResNet50 Loss = 0.4105, Error = 17.20%\n",
      "Batch 500: ResNet50 Loss = 0.3956, Error = 17.12%\n",
      "Batch 600: ResNet50 Loss = 0.4141, Error = 19.68%\n",
      "Batch 700: ResNet50 Loss = 0.4084, Error = 17.61%\n",
      "Batch 800: ResNet50 Loss = 0.3871, Error = 18.62%\n",
      "Batch 900: ResNet50 Loss = 0.4321, Error = 18.01%\n",
      "Batch 1000: ResNet50 Loss = 0.4124, Error = 18.20%\n",
      "Batch 1100: ResNet50 Loss = 0.4270, Error = 20.50%\n",
      "Batch 1200: ResNet50 Loss = 0.4024, Error = 18.48%\n",
      "\n",
      "Epoch 26/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.4288, Error = 20.03%\n",
      "Batch 200: ResNet50 Loss = 0.3741, Error = 19.79%\n",
      "Batch 300: ResNet50 Loss = 0.3750, Error = 18.55%\n",
      "Batch 400: ResNet50 Loss = 0.4074, Error = 18.30%\n",
      "Batch 500: ResNet50 Loss = 0.3982, Error = 19.20%\n",
      "Batch 600: ResNet50 Loss = 0.4004, Error = 17.72%\n",
      "Batch 700: ResNet50 Loss = 0.3866, Error = 19.00%\n",
      "Batch 800: ResNet50 Loss = 0.4218, Error = 17.78%\n",
      "Batch 900: ResNet50 Loss = 0.4086, Error = 18.62%\n",
      "Batch 1000: ResNet50 Loss = 0.4370, Error = 18.94%\n",
      "Batch 1100: ResNet50 Loss = 0.4016, Error = 16.87%\n",
      "Batch 1200: ResNet50 Loss = 0.3831, Error = 17.60%\n",
      "\n",
      "Epoch 27/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.4027, Error = 16.73%\n",
      "Batch 200: ResNet50 Loss = 0.4123, Error = 20.97%\n",
      "Batch 300: ResNet50 Loss = 0.3834, Error = 17.37%\n",
      "Batch 400: ResNet50 Loss = 0.3949, Error = 19.91%\n",
      "Batch 500: ResNet50 Loss = 0.4078, Error = 16.93%\n",
      "Batch 600: ResNet50 Loss = 0.4161, Error = 20.32%\n",
      "Batch 700: ResNet50 Loss = 0.3973, Error = 18.65%\n",
      "Batch 800: ResNet50 Loss = 0.3700, Error = 16.99%\n",
      "Batch 900: ResNet50 Loss = 0.3899, Error = 18.84%\n",
      "Batch 1000: ResNet50 Loss = 0.3920, Error = 16.63%\n",
      "Batch 1100: ResNet50 Loss = 0.3860, Error = 18.92%\n",
      "Batch 1200: ResNet50 Loss = 0.3914, Error = 18.08%\n",
      "\n",
      "Epoch 28/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.4195, Error = 18.11%\n",
      "Batch 200: ResNet50 Loss = 0.3864, Error = 18.80%\n",
      "Batch 300: ResNet50 Loss = 0.3397, Error = 18.15%\n",
      "Batch 400: ResNet50 Loss = 0.3611, Error = 17.46%\n",
      "Batch 500: ResNet50 Loss = 0.3652, Error = 17.41%\n",
      "Batch 600: ResNet50 Loss = 0.3511, Error = 18.12%\n",
      "Batch 700: ResNet50 Loss = 0.3566, Error = 16.40%\n",
      "Batch 800: ResNet50 Loss = 0.3652, Error = 16.98%\n",
      "Batch 900: ResNet50 Loss = 0.4074, Error = 18.66%\n",
      "Batch 1000: ResNet50 Loss = 0.3626, Error = 16.74%\n",
      "Batch 1100: ResNet50 Loss = 0.3773, Error = 16.93%\n",
      "Batch 1200: ResNet50 Loss = 0.3693, Error = 17.46%\n",
      "\n",
      "Epoch 29/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.3948, Error = 17.50%\n",
      "Batch 200: ResNet50 Loss = 0.3528, Error = 18.23%\n",
      "Batch 300: ResNet50 Loss = 0.3559, Error = 16.61%\n",
      "Batch 400: ResNet50 Loss = 0.3749, Error = 16.72%\n",
      "Batch 500: ResNet50 Loss = 0.3513, Error = 17.92%\n",
      "Batch 600: ResNet50 Loss = 0.3551, Error = 16.91%\n",
      "Batch 700: ResNet50 Loss = 0.3908, Error = 18.94%\n",
      "Batch 800: ResNet50 Loss = 0.3763, Error = 18.76%\n",
      "Batch 900: ResNet50 Loss = 0.3583, Error = 16.73%\n",
      "Batch 1000: ResNet50 Loss = 0.3725, Error = 16.31%\n",
      "Batch 1100: ResNet50 Loss = 0.3509, Error = 17.77%\n",
      "Batch 1200: ResNet50 Loss = 0.3248, Error = 16.75%\n",
      "\n",
      "Epoch 30/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.3788, Error = 17.56%\n",
      "Batch 200: ResNet50 Loss = 0.3165, Error = 18.57%\n",
      "Batch 300: ResNet50 Loss = 0.3505, Error = 16.93%\n",
      "Batch 400: ResNet50 Loss = 0.3609, Error = 16.52%\n",
      "Batch 500: ResNet50 Loss = 0.3727, Error = 17.08%\n",
      "Batch 600: ResNet50 Loss = 0.3456, Error = 17.72%\n",
      "Batch 700: ResNet50 Loss = 0.3444, Error = 17.61%\n",
      "Batch 800: ResNet50 Loss = 0.3765, Error = 18.31%\n",
      "Batch 900: ResNet50 Loss = 0.3659, Error = 15.23%\n",
      "Batch 1000: ResNet50 Loss = 0.3390, Error = 16.62%\n",
      "Batch 1100: ResNet50 Loss = 0.3561, Error = 18.39%\n",
      "Batch 1200: ResNet50 Loss = 0.3429, Error = 18.45%\n",
      "\n",
      "Epoch 31/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.3678, Error = 16.93%\n",
      "Batch 200: ResNet50 Loss = 0.3087, Error = 18.13%\n",
      "Batch 300: ResNet50 Loss = 0.3586, Error = 15.74%\n",
      "Batch 400: ResNet50 Loss = 0.3184, Error = 16.73%\n",
      "Batch 500: ResNet50 Loss = 0.3579, Error = 15.95%\n",
      "Batch 600: ResNet50 Loss = 0.3498, Error = 17.95%\n",
      "Batch 700: ResNet50 Loss = 0.3434, Error = 18.73%\n",
      "Batch 800: ResNet50 Loss = 0.3462, Error = 15.00%\n",
      "Batch 900: ResNet50 Loss = 0.3264, Error = 17.41%\n",
      "Batch 1000: ResNet50 Loss = 0.3332, Error = 16.10%\n",
      "Batch 1100: ResNet50 Loss = 0.3538, Error = 17.02%\n",
      "Batch 1200: ResNet50 Loss = 0.3525, Error = 16.79%\n",
      "\n",
      "Epoch 32/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.3371, Error = 15.31%\n",
      "Batch 200: ResNet50 Loss = 0.3370, Error = 17.86%\n",
      "Batch 300: ResNet50 Loss = 0.3142, Error = 15.83%\n",
      "Batch 400: ResNet50 Loss = 0.3130, Error = 16.97%\n",
      "Batch 500: ResNet50 Loss = 0.3321, Error = 16.49%\n",
      "Batch 600: ResNet50 Loss = 0.3134, Error = 17.07%\n",
      "Batch 700: ResNet50 Loss = 0.3354, Error = 18.24%\n",
      "Batch 800: ResNet50 Loss = 0.3332, Error = 16.47%\n",
      "Batch 900: ResNet50 Loss = 0.3267, Error = 16.23%\n",
      "Batch 1000: ResNet50 Loss = 0.3028, Error = 17.29%\n",
      "Batch 1100: ResNet50 Loss = 0.3338, Error = 17.83%\n",
      "Batch 1200: ResNet50 Loss = 0.3522, Error = 16.26%\n",
      "\n",
      "Epoch 33/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.3521, Error = 15.79%\n",
      "Batch 200: ResNet50 Loss = 0.2912, Error = 16.39%\n",
      "Batch 300: ResNet50 Loss = 0.2947, Error = 16.13%\n",
      "Batch 400: ResNet50 Loss = 0.3218, Error = 15.79%\n",
      "Batch 500: ResNet50 Loss = 0.2977, Error = 17.87%\n",
      "Batch 600: ResNet50 Loss = 0.3087, Error = 16.15%\n",
      "Batch 700: ResNet50 Loss = 0.3304, Error = 16.61%\n",
      "Batch 800: ResNet50 Loss = 0.3171, Error = 16.71%\n",
      "Batch 900: ResNet50 Loss = 0.3086, Error = 15.93%\n",
      "Batch 1000: ResNet50 Loss = 0.3039, Error = 17.18%\n",
      "Batch 1100: ResNet50 Loss = 0.3457, Error = 17.21%\n",
      "Batch 1200: ResNet50 Loss = 0.3183, Error = 15.47%\n",
      "\n",
      "Epoch 34/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.3314, Error = 15.32%\n",
      "Batch 200: ResNet50 Loss = 0.2996, Error = 17.37%\n",
      "Batch 300: ResNet50 Loss = 0.3017, Error = 15.87%\n",
      "Batch 400: ResNet50 Loss = 0.3127, Error = 18.14%\n",
      "Batch 500: ResNet50 Loss = 0.3188, Error = 16.14%\n",
      "Batch 600: ResNet50 Loss = 0.2900, Error = 15.16%\n",
      "Batch 700: ResNet50 Loss = 0.3293, Error = 16.26%\n",
      "Batch 800: ResNet50 Loss = 0.2967, Error = 16.62%\n",
      "Batch 900: ResNet50 Loss = 0.3083, Error = 15.44%\n",
      "Batch 1000: ResNet50 Loss = 0.3015, Error = 16.43%\n",
      "Batch 1100: ResNet50 Loss = 0.2998, Error = 17.72%\n",
      "Batch 1200: ResNet50 Loss = 0.2887, Error = 15.43%\n",
      "\n",
      "Epoch 35/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.3315, Error = 14.81%\n",
      "Batch 200: ResNet50 Loss = 0.3131, Error = 16.14%\n",
      "Batch 300: ResNet50 Loss = 0.2941, Error = 15.16%\n",
      "Batch 400: ResNet50 Loss = 0.2850, Error = 15.43%\n",
      "Batch 500: ResNet50 Loss = 0.2933, Error = 15.78%\n",
      "Batch 600: ResNet50 Loss = 0.3039, Error = 16.77%\n",
      "Batch 700: ResNet50 Loss = 0.3171, Error = 15.98%\n",
      "Batch 800: ResNet50 Loss = 0.2694, Error = 15.86%\n",
      "Batch 900: ResNet50 Loss = 0.2755, Error = 16.21%\n",
      "Batch 1000: ResNet50 Loss = 0.3109, Error = 16.47%\n",
      "Batch 1100: ResNet50 Loss = 0.3244, Error = 17.12%\n",
      "Batch 1200: ResNet50 Loss = 0.3053, Error = 16.33%\n",
      "\n",
      "Epoch 36/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.3335, Error = 17.14%\n",
      "Batch 200: ResNet50 Loss = 0.2756, Error = 15.02%\n",
      "Batch 300: ResNet50 Loss = 0.2831, Error = 15.06%\n",
      "Batch 400: ResNet50 Loss = 0.2886, Error = 15.84%\n",
      "Batch 500: ResNet50 Loss = 0.2732, Error = 15.91%\n",
      "Batch 600: ResNet50 Loss = 0.2982, Error = 15.62%\n",
      "Batch 700: ResNet50 Loss = 0.3012, Error = 15.74%\n",
      "Batch 800: ResNet50 Loss = 0.3098, Error = 16.90%\n",
      "Batch 900: ResNet50 Loss = 0.2610, Error = 16.26%\n",
      "Batch 1000: ResNet50 Loss = 0.2863, Error = 15.61%\n",
      "Batch 1100: ResNet50 Loss = 0.2883, Error = 19.45%\n",
      "Batch 1200: ResNet50 Loss = 0.2969, Error = 14.96%\n",
      "\n",
      "Epoch 37/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.3503, Error = 17.59%\n",
      "Batch 200: ResNet50 Loss = 0.2837, Error = 15.52%\n",
      "Batch 300: ResNet50 Loss = 0.2465, Error = 14.64%\n",
      "Batch 400: ResNet50 Loss = 0.2502, Error = 15.02%\n",
      "Batch 500: ResNet50 Loss = 0.2857, Error = 16.69%\n",
      "Batch 600: ResNet50 Loss = 0.2700, Error = 15.35%\n",
      "Batch 700: ResNet50 Loss = 0.2910, Error = 15.80%\n",
      "Batch 800: ResNet50 Loss = 0.2823, Error = 16.87%\n",
      "Batch 900: ResNet50 Loss = 0.2707, Error = 14.42%\n",
      "Batch 1000: ResNet50 Loss = 0.2584, Error = 15.62%\n",
      "Batch 1100: ResNet50 Loss = 0.2963, Error = 14.23%\n",
      "Batch 1200: ResNet50 Loss = 0.2677, Error = 16.41%\n",
      "\n",
      "Epoch 38/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.2892, Error = 14.42%\n",
      "Batch 200: ResNet50 Loss = 0.2829, Error = 16.29%\n",
      "Batch 300: ResNet50 Loss = 0.2456, Error = 15.80%\n",
      "Batch 400: ResNet50 Loss = 0.2877, Error = 15.75%\n",
      "Batch 500: ResNet50 Loss = 0.2662, Error = 15.10%\n",
      "Batch 600: ResNet50 Loss = 0.2553, Error = 15.83%\n",
      "Batch 700: ResNet50 Loss = 0.2700, Error = 15.28%\n",
      "Batch 800: ResNet50 Loss = 0.2520, Error = 15.58%\n",
      "Batch 900: ResNet50 Loss = 0.2647, Error = 14.80%\n",
      "Batch 1000: ResNet50 Loss = 0.2745, Error = 14.86%\n",
      "Batch 1100: ResNet50 Loss = 0.2763, Error = 14.86%\n",
      "Batch 1200: ResNet50 Loss = 0.2654, Error = 15.44%\n",
      "\n",
      "Epoch 39/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.2955, Error = 16.15%\n",
      "Batch 200: ResNet50 Loss = 0.2933, Error = 16.10%\n",
      "Batch 300: ResNet50 Loss = 0.2531, Error = 16.08%\n",
      "Batch 400: ResNet50 Loss = 0.2647, Error = 15.06%\n",
      "Batch 500: ResNet50 Loss = 0.2716, Error = 16.67%\n",
      "Batch 600: ResNet50 Loss = 0.2532, Error = 16.34%\n",
      "Batch 700: ResNet50 Loss = 0.2467, Error = 15.58%\n",
      "Batch 800: ResNet50 Loss = 0.2670, Error = 14.45%\n",
      "Batch 900: ResNet50 Loss = 0.2283, Error = 15.41%\n",
      "Batch 1000: ResNet50 Loss = 0.2791, Error = 14.68%\n",
      "Batch 1100: ResNet50 Loss = 0.2496, Error = 15.80%\n",
      "Batch 1200: ResNet50 Loss = 0.2710, Error = 15.93%\n",
      "\n",
      "Epoch 40/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.2566, Error = 14.01%\n",
      "Batch 200: ResNet50 Loss = 0.2252, Error = 15.03%\n",
      "Batch 300: ResNet50 Loss = 0.2329, Error = 14.45%\n",
      "Batch 400: ResNet50 Loss = 0.2424, Error = 14.51%\n",
      "Batch 500: ResNet50 Loss = 0.2521, Error = 14.71%\n",
      "Batch 600: ResNet50 Loss = 0.2333, Error = 15.83%\n",
      "Batch 700: ResNet50 Loss = 0.2514, Error = 14.84%\n",
      "Batch 800: ResNet50 Loss = 0.2405, Error = 16.14%\n",
      "Batch 900: ResNet50 Loss = 0.2792, Error = 14.52%\n",
      "Batch 1000: ResNet50 Loss = 0.2524, Error = 14.70%\n",
      "Batch 1100: ResNet50 Loss = 0.2535, Error = 15.96%\n",
      "Batch 1200: ResNet50 Loss = 0.2686, Error = 15.84%\n",
      "\n",
      "Epoch 41/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.2630, Error = 15.19%\n",
      "Batch 200: ResNet50 Loss = 0.2146, Error = 15.19%\n",
      "Batch 300: ResNet50 Loss = 0.2485, Error = 15.33%\n",
      "Batch 400: ResNet50 Loss = 0.2236, Error = 16.64%\n",
      "Batch 500: ResNet50 Loss = 0.2647, Error = 15.64%\n",
      "Batch 600: ResNet50 Loss = 0.2271, Error = 14.85%\n",
      "Batch 700: ResNet50 Loss = 0.2567, Error = 15.23%\n",
      "Batch 800: ResNet50 Loss = 0.2335, Error = 16.47%\n",
      "Batch 900: ResNet50 Loss = 0.2221, Error = 14.65%\n",
      "Batch 1000: ResNet50 Loss = 0.2567, Error = 15.10%\n",
      "Batch 1100: ResNet50 Loss = 0.2419, Error = 16.27%\n",
      "Batch 1200: ResNet50 Loss = 0.2510, Error = 15.38%\n",
      "\n",
      "Epoch 42/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.2670, Error = 15.23%\n",
      "Batch 200: ResNet50 Loss = 0.2470, Error = 14.03%\n",
      "Batch 300: ResNet50 Loss = 0.2422, Error = 16.28%\n",
      "Batch 400: ResNet50 Loss = 0.2546, Error = 15.31%\n",
      "Batch 500: ResNet50 Loss = 0.2341, Error = 15.57%\n",
      "Batch 600: ResNet50 Loss = 0.2401, Error = 14.95%\n",
      "Batch 700: ResNet50 Loss = 0.2474, Error = 14.96%\n",
      "Batch 800: ResNet50 Loss = 0.2363, Error = 14.48%\n",
      "Batch 900: ResNet50 Loss = 0.2366, Error = 16.27%\n",
      "Batch 1000: ResNet50 Loss = 0.2456, Error = 15.71%\n",
      "Batch 1100: ResNet50 Loss = 0.2600, Error = 14.70%\n",
      "Batch 1200: ResNet50 Loss = 0.2254, Error = 14.65%\n",
      "\n",
      "Epoch 43/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.2588, Error = 14.65%\n",
      "Batch 200: ResNet50 Loss = 0.2254, Error = 14.71%\n",
      "Batch 300: ResNet50 Loss = 0.2124, Error = 14.23%\n",
      "Batch 400: ResNet50 Loss = 0.2131, Error = 15.98%\n",
      "Batch 500: ResNet50 Loss = 0.2530, Error = 14.40%\n",
      "Batch 600: ResNet50 Loss = 0.2266, Error = 15.48%\n",
      "Batch 700: ResNet50 Loss = 0.2259, Error = 15.43%\n",
      "Batch 800: ResNet50 Loss = 0.2134, Error = 14.27%\n",
      "Batch 900: ResNet50 Loss = 0.2281, Error = 14.50%\n",
      "Batch 1000: ResNet50 Loss = 0.2268, Error = 14.72%\n",
      "Batch 1100: ResNet50 Loss = 0.2150, Error = 14.93%\n",
      "Batch 1200: ResNet50 Loss = 0.2357, Error = 15.33%\n",
      "\n",
      "Epoch 44/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.2679, Error = 14.30%\n",
      "Batch 200: ResNet50 Loss = 0.2143, Error = 14.11%\n",
      "Batch 300: ResNet50 Loss = 0.2050, Error = 14.23%\n",
      "Batch 400: ResNet50 Loss = 0.2185, Error = 14.46%\n",
      "Batch 500: ResNet50 Loss = 0.2184, Error = 15.14%\n",
      "Batch 600: ResNet50 Loss = 0.2371, Error = 13.84%\n",
      "Batch 700: ResNet50 Loss = 0.2270, Error = 15.77%\n",
      "Batch 800: ResNet50 Loss = 0.2341, Error = 16.31%\n",
      "Batch 900: ResNet50 Loss = 0.2202, Error = 15.66%\n",
      "Batch 1000: ResNet50 Loss = 0.2135, Error = 14.07%\n",
      "Batch 1100: ResNet50 Loss = 0.2147, Error = 13.88%\n",
      "Batch 1200: ResNet50 Loss = 0.2340, Error = 15.38%\n",
      "\n",
      "Epoch 45/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.2532, Error = 13.85%\n",
      "Batch 200: ResNet50 Loss = 0.2008, Error = 15.87%\n",
      "Batch 300: ResNet50 Loss = 0.1989, Error = 14.50%\n",
      "Batch 400: ResNet50 Loss = 0.2295, Error = 14.78%\n",
      "Batch 500: ResNet50 Loss = 0.2224, Error = 14.26%\n",
      "Batch 600: ResNet50 Loss = 0.2024, Error = 15.17%\n",
      "Batch 700: ResNet50 Loss = 0.1856, Error = 14.84%\n",
      "Batch 800: ResNet50 Loss = 0.2146, Error = 14.52%\n",
      "Batch 900: ResNet50 Loss = 0.2230, Error = 14.31%\n",
      "Batch 1000: ResNet50 Loss = 0.2203, Error = 14.93%\n",
      "Batch 1100: ResNet50 Loss = 0.2154, Error = 14.82%\n",
      "Batch 1200: ResNet50 Loss = 0.2244, Error = 14.95%\n",
      "\n",
      "Epoch 46/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.2570, Error = 13.34%\n",
      "Batch 200: ResNet50 Loss = 0.1928, Error = 13.99%\n",
      "Batch 300: ResNet50 Loss = 0.2046, Error = 14.91%\n",
      "Batch 400: ResNet50 Loss = 0.2024, Error = 14.89%\n",
      "Batch 500: ResNet50 Loss = 0.2200, Error = 15.04%\n",
      "Batch 600: ResNet50 Loss = 0.2115, Error = 16.08%\n",
      "Batch 700: ResNet50 Loss = 0.1989, Error = 13.95%\n",
      "Batch 800: ResNet50 Loss = 0.1666, Error = 15.01%\n",
      "Batch 900: ResNet50 Loss = 0.2048, Error = 13.46%\n",
      "Batch 1000: ResNet50 Loss = 0.1997, Error = 15.05%\n",
      "Batch 1100: ResNet50 Loss = 0.2369, Error = 14.39%\n",
      "Batch 1200: ResNet50 Loss = 0.2046, Error = 14.71%\n",
      "\n",
      "Epoch 47/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.2300, Error = 14.72%\n",
      "Batch 200: ResNet50 Loss = 0.2146, Error = 14.50%\n",
      "Batch 300: ResNet50 Loss = 0.1890, Error = 15.06%\n",
      "Batch 400: ResNet50 Loss = 0.1811, Error = 13.82%\n",
      "Batch 500: ResNet50 Loss = 0.2091, Error = 15.39%\n",
      "Batch 600: ResNet50 Loss = 0.1857, Error = 16.35%\n",
      "Batch 700: ResNet50 Loss = 0.2127, Error = 14.11%\n",
      "Batch 800: ResNet50 Loss = 0.2284, Error = 15.24%\n",
      "Batch 900: ResNet50 Loss = 0.2119, Error = 14.34%\n",
      "Batch 1000: ResNet50 Loss = 0.2169, Error = 15.83%\n",
      "Batch 1100: ResNet50 Loss = 0.1937, Error = 13.56%\n",
      "Batch 1200: ResNet50 Loss = 0.2099, Error = 15.24%\n",
      "\n",
      "Epoch 48/100\n",
      "Current LR - ResNet50: 0.001000\n",
      "Batch 100: ResNet50 Loss = 0.2502, Error = 14.13%\n",
      "Batch 200: ResNet50 Loss = 0.1852, Error = 14.19%\n",
      "Batch 300: ResNet50 Loss = 0.1648, Error = 15.26%\n",
      "Batch 400: ResNet50 Loss = 0.1910, Error = 14.37%\n",
      "Batch 500: ResNet50 Loss = 0.1884, Error = 14.06%\n",
      "Batch 600: ResNet50 Loss = 0.1827, Error = 13.78%\n",
      "Batch 700: ResNet50 Loss = 0.1949, Error = 14.47%\n",
      "Batch 800: ResNet50 Loss = 0.2118, Error = 15.05%\n",
      "Batch 900: ResNet50 Loss = 0.1921, Error = 14.67%\n",
      "Batch 1000: ResNet50 Loss = 0.1805, Error = 14.10%\n",
      "Batch 1100: ResNet50 Loss = 0.2015, Error = 14.49%\n",
      "Batch 1200: ResNet50 Loss = 0.2206, Error = 14.87%\n",
      "\n",
      "Epoch 49/100\n",
      "Current LR - ResNet50: 0.000100\n",
      "Batch 100: ResNet50 Loss = 0.2024, Error = 12.78%\n",
      "Batch 200: ResNet50 Loss = 0.1279, Error = 12.36%\n",
      "Batch 300: ResNet50 Loss = 0.1057, Error = 12.40%\n",
      "Batch 400: ResNet50 Loss = 0.1089, Error = 12.22%\n",
      "Batch 500: ResNet50 Loss = 0.1119, Error = 12.21%\n",
      "Batch 600: ResNet50 Loss = 0.1119, Error = 11.73%\n",
      "Batch 700: ResNet50 Loss = 0.1061, Error = 12.18%\n",
      "Batch 800: ResNet50 Loss = 0.1064, Error = 12.18%\n",
      "Batch 900: ResNet50 Loss = 0.0955, Error = 12.27%\n",
      "Batch 1000: ResNet50 Loss = 0.0956, Error = 12.08%\n",
      "Batch 1100: ResNet50 Loss = 0.1023, Error = 12.05%\n",
      "Batch 1200: ResNet50 Loss = 0.0849, Error = 11.85%\n",
      "\n",
      "Epoch 50/100\n",
      "Current LR - ResNet50: 0.000100\n",
      "Batch 100: ResNet50 Loss = 0.1930, Error = 12.22%\n",
      "Batch 200: ResNet50 Loss = 0.1195, Error = 12.08%\n",
      "Batch 300: ResNet50 Loss = 0.0986, Error = 12.42%\n",
      "Batch 400: ResNet50 Loss = 0.1027, Error = 12.05%\n",
      "Batch 500: ResNet50 Loss = 0.0944, Error = 12.14%\n",
      "Batch 600: ResNet50 Loss = 0.0960, Error = 12.37%\n",
      "Batch 700: ResNet50 Loss = 0.1018, Error = 12.26%\n",
      "Batch 800: ResNet50 Loss = 0.1001, Error = 12.01%\n",
      "Batch 900: ResNet50 Loss = 0.0866, Error = 11.95%\n",
      "Batch 1000: ResNet50 Loss = 0.0797, Error = 12.03%\n",
      "Batch 1100: ResNet50 Loss = 0.0841, Error = 12.00%\n",
      "Batch 1200: ResNet50 Loss = 0.0846, Error = 12.21%\n",
      "\n",
      "Epoch 51/100\n",
      "Current LR - ResNet50: 0.000100\n",
      "Batch 100: ResNet50 Loss = 0.1835, Error = 12.54%\n",
      "Batch 200: ResNet50 Loss = 0.1012, Error = 12.23%\n",
      "Batch 300: ResNet50 Loss = 0.0907, Error = 12.49%\n",
      "Batch 400: ResNet50 Loss = 0.1033, Error = 12.41%\n",
      "Batch 500: ResNet50 Loss = 0.0974, Error = 12.11%\n",
      "Batch 600: ResNet50 Loss = 0.0906, Error = 12.19%\n",
      "Batch 700: ResNet50 Loss = 0.0848, Error = 12.01%\n",
      "Batch 800: ResNet50 Loss = 0.0867, Error = 12.10%\n",
      "Batch 900: ResNet50 Loss = 0.0863, Error = 11.78%\n",
      "Batch 1000: ResNet50 Loss = 0.0939, Error = 11.78%\n",
      "Batch 1100: ResNet50 Loss = 0.0930, Error = 12.10%\n",
      "Batch 1200: ResNet50 Loss = 0.0960, Error = 11.85%\n",
      "\n",
      "Epoch 52/100\n",
      "Current LR - ResNet50: 0.000100\n",
      "Batch 100: ResNet50 Loss = 0.1749, Error = 12.98%\n",
      "Batch 200: ResNet50 Loss = 0.1154, Error = 12.42%\n",
      "Batch 300: ResNet50 Loss = 0.1011, Error = 12.07%\n",
      "Batch 400: ResNet50 Loss = 0.0930, Error = 12.07%\n",
      "Batch 500: ResNet50 Loss = 0.0908, Error = 12.32%\n",
      "Batch 600: ResNet50 Loss = 0.0802, Error = 12.12%\n",
      "Batch 700: ResNet50 Loss = 0.0761, Error = 12.09%\n",
      "Batch 800: ResNet50 Loss = 0.0865, Error = 12.12%\n",
      "Batch 900: ResNet50 Loss = 0.0891, Error = 12.14%\n",
      "Batch 1000: ResNet50 Loss = 0.0870, Error = 11.47%\n",
      "Batch 1100: ResNet50 Loss = 0.0717, Error = 12.43%\n",
      "Batch 1200: ResNet50 Loss = 0.0871, Error = 12.32%\n",
      "\n",
      "Epoch 53/100\n",
      "Current LR - ResNet50: 0.000100\n",
      "Batch 100: ResNet50 Loss = 0.1845, Error = 12.94%\n",
      "Batch 200: ResNet50 Loss = 0.1037, Error = 12.38%\n",
      "Batch 300: ResNet50 Loss = 0.0918, Error = 12.18%\n",
      "Batch 400: ResNet50 Loss = 0.0785, Error = 11.98%\n",
      "Batch 500: ResNet50 Loss = 0.0800, Error = 12.19%\n",
      "Batch 600: ResNet50 Loss = 0.0846, Error = 12.26%\n",
      "Batch 700: ResNet50 Loss = 0.0870, Error = 12.26%\n",
      "Batch 800: ResNet50 Loss = 0.0797, Error = 12.38%\n",
      "Batch 900: ResNet50 Loss = 0.0808, Error = 12.34%\n",
      "Batch 1000: ResNet50 Loss = 0.0694, Error = 12.04%\n",
      "Batch 1100: ResNet50 Loss = 0.0789, Error = 11.77%\n",
      "Batch 1200: ResNet50 Loss = 0.0860, Error = 12.33%\n",
      "\n",
      "Epoch 54/100\n",
      "Current LR - ResNet50: 0.000100\n",
      "Batch 100: ResNet50 Loss = 0.1634, Error = 12.88%\n",
      "Batch 200: ResNet50 Loss = 0.1004, Error = 12.34%\n",
      "Batch 300: ResNet50 Loss = 0.0845, Error = 12.41%\n",
      "Batch 400: ResNet50 Loss = 0.0818, Error = 12.44%\n",
      "Batch 500: ResNet50 Loss = 0.0764, Error = 11.88%\n",
      "Batch 600: ResNet50 Loss = 0.0751, Error = 12.25%\n",
      "Batch 700: ResNet50 Loss = 0.0725, Error = 12.05%\n",
      "Batch 800: ResNet50 Loss = 0.0911, Error = 12.28%\n",
      "Batch 900: ResNet50 Loss = 0.0777, Error = 11.97%\n",
      "Batch 1000: ResNet50 Loss = 0.0734, Error = 12.39%\n",
      "Batch 1100: ResNet50 Loss = 0.0867, Error = 11.65%\n",
      "Batch 1200: ResNet50 Loss = 0.0788, Error = 11.72%\n",
      "\n",
      "Epoch 55/100\n",
      "Current LR - ResNet50: 0.000100\n",
      "Batch 100: ResNet50 Loss = 0.1823, Error = 12.46%\n",
      "Batch 200: ResNet50 Loss = 0.0984, Error = 12.09%\n",
      "Batch 300: ResNet50 Loss = 0.0866, Error = 11.84%\n",
      "Batch 400: ResNet50 Loss = 0.0843, Error = 12.03%\n",
      "Batch 500: ResNet50 Loss = 0.0782, Error = 11.90%\n",
      "Batch 600: ResNet50 Loss = 0.0722, Error = 11.93%\n",
      "Batch 700: ResNet50 Loss = 0.0762, Error = 12.09%\n",
      "Batch 800: ResNet50 Loss = 0.0762, Error = 11.83%\n",
      "Batch 900: ResNet50 Loss = 0.0722, Error = 12.37%\n",
      "Batch 1000: ResNet50 Loss = 0.0893, Error = 12.15%\n",
      "Batch 1100: ResNet50 Loss = 0.0690, Error = 12.16%\n",
      "Batch 1200: ResNet50 Loss = 0.0923, Error = 12.04%\n",
      "\n",
      "Epoch 56/100\n",
      "Current LR - ResNet50: 0.000100\n",
      "Batch 100: ResNet50 Loss = 0.1705, Error = 13.01%\n",
      "Batch 200: ResNet50 Loss = 0.0955, Error = 11.86%\n",
      "Batch 300: ResNet50 Loss = 0.0796, Error = 12.20%\n",
      "Batch 400: ResNet50 Loss = 0.0819, Error = 11.72%\n",
      "Batch 500: ResNet50 Loss = 0.0741, Error = 12.28%\n",
      "Batch 600: ResNet50 Loss = 0.0827, Error = 12.43%\n",
      "Batch 700: ResNet50 Loss = 0.0720, Error = 12.03%\n",
      "Batch 800: ResNet50 Loss = 0.0826, Error = 12.21%\n",
      "Batch 900: ResNet50 Loss = 0.0712, Error = 11.68%\n",
      "Batch 1000: ResNet50 Loss = 0.0779, Error = 11.80%\n",
      "Batch 1100: ResNet50 Loss = 0.0816, Error = 11.81%\n",
      "Batch 1200: ResNet50 Loss = 0.0866, Error = 12.08%\n",
      "\n",
      "Epoch 57/100\n",
      "Current LR - ResNet50: 0.000100\n",
      "Batch 100: ResNet50 Loss = 0.1727, Error = 12.93%\n",
      "Batch 200: ResNet50 Loss = 0.0890, Error = 12.53%\n",
      "Batch 300: ResNet50 Loss = 0.0668, Error = 12.21%\n",
      "Batch 400: ResNet50 Loss = 0.0780, Error = 11.97%\n",
      "Batch 500: ResNet50 Loss = 0.0809, Error = 12.53%\n",
      "Batch 600: ResNet50 Loss = 0.0808, Error = 12.56%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# 100 배치마다 검증 및 출력\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (i + \u001b[32m1\u001b[39m) % \u001b[32m100\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     val_error_resnet_50 = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresnet_50\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     resnet_50_error.append(val_error_resnet_50)\n\u001b[32m     33\u001b[39m     avg_loss_resnet_50 = running_loss_resnet_50 / \u001b[32m100\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, data_loader, is_top5)\u001b[39m\n\u001b[32m      5\u001b[39m total_samples = \u001b[32m0\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# GPU로 이동\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# GPU로 이동\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\workspace-vom\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\workspace-vom\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\workspace-vom\\env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\workspace-vom\\env\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:416\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\workspace-vom\\env\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:119\u001b[39m, in \u001b[36mCIFAR10.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    116\u001b[39m img = Image.fromarray(img)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    122\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.target_transform(target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\workspace-vom\\env\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\workspace-vom\\env\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[39m, in \u001b[36mToTensor.__call__\u001b[39m\u001b[34m(self, pic)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[32m    130\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m \u001b[33;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\work\\workspace-vom\\env\\Lib\\site-packages\\torchvision\\transforms\\functional.py:172\u001b[39m, in \u001b[36mto_tensor\u001b[39m\u001b[34m(pic)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pic.mode == \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    171\u001b[39m     img = \u001b[32m255\u001b[39m * img\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m img = \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpic\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF_pil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_image_num_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[32m    174\u001b[39m img = img.permute((\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)).contiguous()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ResNet-50 model 학습 (Mixed Precision 적용)\n",
    "for epoch in range(num_epochs):\n",
    "    # 모델을 학습 모드로 설정\n",
    "    resnet_50.train()\n",
    "    \n",
    "    running_loss_resnet_50 = 0.0\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Current LR - ResNet50: {resnet_50_optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)  # GPU로 이동\n",
    "        labels = labels.to(device)  # GPU로 이동\n",
    "\n",
    "        # ResNet-50 학습 (Mixed Precision)\n",
    "        resnet_50_optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed Precision 순전파\n",
    "        with autocast('cuda'):\n",
    "            outputs_resnet_50 = resnet_50(inputs)\n",
    "            loss_resnet_50 = criterion(outputs_resnet_50, labels)\n",
    "        \n",
    "        # Mixed Precision 역전파\n",
    "        scaler_resnet_50.scale(loss_resnet_50).backward()\n",
    "        scaler_resnet_50.step(resnet_50_optimizer)\n",
    "        scaler_resnet_50.update()\n",
    "\n",
    "        # 배치 손실 합계 계산\n",
    "        running_loss_resnet_50 += loss_resnet_50.item()\n",
    "\n",
    "        # 20 배치마다 검증 및 출력\n",
    "        if (i + 1) % 20 == 0:\n",
    "            val_error_resnet_50 = evaluate_model(resnet_50, val_loader)\n",
    "\n",
    "            resnet_50_error.append(val_error_resnet_50)\n",
    "\n",
    "            avg_loss_resnet_50 = running_loss_resnet_50 / 20\n",
    "            \n",
    "            resnet_50_loss.append(avg_loss_resnet_50)\n",
    "\n",
    "            print(f\"Batch {i + 1}: ResNet50 Loss = {avg_loss_resnet_50:.4f}, Error = {val_error_resnet_50:.2f}%\")\n",
    "            \n",
    "            # running_loss 초기화\n",
    "            running_loss_resnet_50 = 0.0\n",
    "    \n",
    "    # 에포크 끝에서 스케줄러 업데이트 (검증 오류율 기준)\n",
    "    if len(resnet_50_error) > 0:\n",
    "        resnet_50_scheduler.step(resnet_50_error[-1])\n",
    "\n",
    "print(\"학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7367384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-50 model 저장\n",
    "torch.save(resnet_50.state_dict(), 'resnet_50.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fafe0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SE-ResNet과 ResNet 비교 그래프\n",
    "plt.figure(figsize=(15, 5))\n",
    "# 손실 비교 그래프\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(se_resnet_50_loss, label='SE-ResNet-50', color='red', linewidth=1)\n",
    "plt.plot(resnet_50_loss, label='ResNet-50', color='green', linewidth=1)\n",
    "plt.title(\"Loss Comparison\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 오류율 step x 값 보정\n",
    "x_values = [i * 24 for i in range(len(resnet_50_error))]\n",
    "\n",
    "# 오류율 비교 그래프\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(x_values, se_resnet_50_error, label='SE-ResNet-50', color='blue', linewidth=2)\n",
    "plt.plot(x_values, resnet_50_error, label='ResNet-50', color='green', linewidth=2)\n",
    "plt.title(\"Error Rate Comparison\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Error (%)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
